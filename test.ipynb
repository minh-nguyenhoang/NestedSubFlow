{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img = cv2.imread('7b8902b02454db97903a146bc9e2121c.jpg', cv2.IMREAD_COLOR)[..., ::-1]\n",
    "h,w,_ = img.shape\n",
    "\n",
    "restored = cv2.resize(cv2.resize(img, (int(h/4), int(h/4))), (w,h), interpolation = cv2.INTER_NEAREST)\n",
    "plt.imshow(restored)\n",
    "\n",
    "cv2.imwrite(\"output.jpg\", restored[..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "grid_i, grid_j = torch.meshgrid(\n",
    "        torch.arange(-2, 4 + 2),\n",
    "        torch.arange(-1, 4 + 1), \n",
    "        indexing='ij'\n",
    "    )\n",
    "grid_coord = torch.cat((grid_i.unsqueeze(2), grid_j.unsqueeze(2)), 2).float() # w,h,2\n",
    "grid_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_coord_im2col = torch.as_strided(grid_coord, \n",
    "                size = (4, 4, 3,3, 2),\n",
    "                stride=(grid_coord.stride(0) * 1, grid_coord.stride(1) * 1, \n",
    "                        grid_coord.stride(0) * 1, grid_coord.stride(1) * 1, \n",
    "                        grid_coord.stride(2)) \n",
    "    )\n",
    "grid_coord_im2col[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 32, 32])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.modules.deform_conv import DeformConv2d, SeparableDeformConv2d\n",
    "import torch \n",
    "conv = SeparableDeformConv2d(16,96, 3, padding= 1, groups= 16)\n",
    "# This 2 conv_offset have the same number of parameter, but their output is different\n",
    "# All output channels will use the same offset map aggregate from all input channels\n",
    "conv_offset = torch.nn.Conv2d(16, 2 * 3 * 3 * 1, 3,1, 1, groups= 1) \n",
    "# Each output channel will use different offset map based on coresponding input channel\n",
    "conv_offset = torch.nn.Conv2d(16, 2 * 3 * 3 * 16, 3,1, 1, groups= 16)\n",
    "x = torch.rand(1,16,32,32)\n",
    "offset =conv_offset(x)\n",
    "\n",
    "out = conv(x, offset)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.flow.nested_flow import NestedAffineCoupling, InvertibleModuleWrapper, AffineCoupling, InvertibleSequential, InvConv2dLU\n",
    "import torch \n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "mod = InvertibleModuleWrapper(NestedAffineCoupling(4, 3, level=1, max_stack_level= 2, enforce_channel_on_base= True), disable= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3967e-06, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(1,16,32,32).double()\n",
    "conv_ = InvertibleSequential(AffineCoupling(16), #InvConv2dLU(16),\n",
    "                             AffineCoupling(16), #InvConv2dLU(16),\n",
    "                             AffineCoupling(16), #InvConv2dLU(16),\n",
    "                             AffineCoupling(16), #InvConv2dLU(16),\n",
    "                             AffineCoupling(16), #InvConv2dLU(16),\n",
    "                             AffineCoupling(16), #InvConv2dLU(16),\n",
    "                             ).double()\n",
    "((conv_.inverse(conv_(x)) - x).abs()).mean()\n",
    "# mod(x, cond).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4866e-08, device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src.modules.flow.nested_flow import NestedAffineCoupling, InvertibleModuleWrapper, AffineCoupling, InvertibleSequential, InvConv2dLU\n",
    "x = torch.rand(5,16,32,32).cuda().double()\n",
    "cond = torch.rand(5,3,32,32).cuda().double()\n",
    "# Still not invertible with max_stack_level != 1. The problem seem to be coming from the numerical error? Still need to investigate more as using double the error still grow exponentially.\n",
    "mod = NestedAffineCoupling(16, None, level=2, max_stack_level= 2, enforce_channel_on_base= True).cuda().double()\n",
    "# ((mod.inverse(mod(x, cond), cond) - x).abs() < 1e-7).all()\n",
    "((mod.inverse(mod(x)) - x).abs()).mean()\n",
    "# mod(x, cond).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7892, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2 = InvertibleModuleWrapper(InvertibleSequential(InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel'), disable = True),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'spatial'), disable = True),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel'), disable = True),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel'), disable = True),\n",
    "                            # InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'spatial')),\n",
    "                            ), disable = True)\n",
    "\n",
    "x2 = torch.rand(1,64,32,32)\n",
    "((mod2.inverse(mod2(x2)) - x2).abs()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type:depth-idx)                                                 Output Shape              Param #\n",
       "========================================================================================================================\n",
       "InvertibleModuleWrapper                                                [1, 64, 128, 128]         --\n",
       "├─NestedAffineCoupling: 1-1                                            [1, 64, 128, 128]         --\n",
       "│    └─ModuleList: 2-6                                                 --                        (recursive)\n",
       "│    │    └─InvertibleSequential: 3-1                                  [1, 64, 128, 128]         16,512\n",
       "│    └─ModuleList: 2-9                                                 --                        (recursive)\n",
       "│    │    └─DenseinResConditionalModule: 3-2                           [1, 32, 128, 128]         9,184\n",
       "│    └─ModuleList: 2-8                                                 --                        (recursive)\n",
       "│    │    └─NestedAffineCoupling: 3-3                                  [1, 32, 128, 128]         377,344\n",
       "│    └─ModuleList: 2-9                                                 --                        (recursive)\n",
       "│    │    └─DenseinResConditionalModule: 3-4                           [1, 32, 128, 128]         (recursive)\n",
       "│    └─ModuleList: 2-10                                                --                        (recursive)\n",
       "│    │    └─NestedAffineCoupling: 3-5                                  [1, 32, 128, 128]         377,344\n",
       "│    └─ModuleList: 2-6                                                 --                        (recursive)\n",
       "│    │    └─InvertibleSequential: 3-6                                  [1, 64, 128, 128]         16,512\n",
       "│    └─ModuleList: 2-9                                                 --                        (recursive)\n",
       "│    │    └─DenseinResConditionalModule: 3-7                           [1, 32, 128, 128]         9,184\n",
       "│    └─ModuleList: 2-8                                                 --                        (recursive)\n",
       "│    │    └─NestedAffineCoupling: 3-8                                  [1, 32, 128, 128]         42,624\n",
       "│    └─ModuleList: 2-9                                                 --                        (recursive)\n",
       "│    │    └─DenseinResConditionalModule: 3-9                           [1, 32, 128, 128]         (recursive)\n",
       "│    └─ModuleList: 2-10                                                --                        (recursive)\n",
       "│    │    └─NestedAffineCoupling: 3-10                                 [1, 32, 128, 128]         42,624\n",
       "========================================================================================================================\n",
       "Total params: 891,328\n",
       "Trainable params: 891,328\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 4.92\n",
       "========================================================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 343.93\n",
       "Params size (MB): 3.57\n",
       "Estimated Total Size (MB): 353.79\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "mod = InvertibleModuleWrapper(NestedAffineCoupling(64, condition_channels=32, level=2, max_stack_level= 2, \n",
    "                                                   constrain_stack = True, custom_masking = None), disable= True)\n",
    "mod._fn.check_total_flow()\n",
    "summary(mod,[(1,64,128,128), (1,32,128,128)], depth= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "InvertibleModuleWrapper                                 [1, 64, 128, 128]         --\n",
       "├─InvertibleSequential: 1-1                             --                        --\n",
       "│    └─InvertibleModuleWrapper: 2-1                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-1                         --                        92,416\n",
       "│    └─InvertibleModuleWrapper: 2-2                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-2                         --                        319,872\n",
       "│    └─InvertibleModuleWrapper: 2-3                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-3                         --                        92,416\n",
       "│    └─InvertibleModuleWrapper: 2-4                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-4                         --                        319,872\n",
       "│    └─InvertibleModuleWrapper: 2-5                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-5                         --                        92,416\n",
       "│    └─InvertibleModuleWrapper: 2-6                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-6                         --                        319,872\n",
       "│    └─InvertibleModuleWrapper: 2-7                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-7                         --                        92,416\n",
       "│    └─InvertibleModuleWrapper: 2-8                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-8                         --                        92,416\n",
       "=========================================================================================================\n",
       "Total params: 1,421,696\n",
       "Trainable params: 1,421,696\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 21.13\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 595.59\n",
       "Params size (MB): 5.69\n",
       "Estimated Total Size (MB): 601.28\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2 = InvertibleModuleWrapper(InvertibleSequential(\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'spatial')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'spatial')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'spatial')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel')),\n",
    "                            ))\n",
    "summary(mod2,[(1,64,128,128)], depth= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1 model took 0.08s\n",
      "Training 5 model took 0.33s\n",
      "Training 15 model took 0.98s\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import time\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, network_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, network_size)\n",
    "        self.fc2 = nn.Linear(network_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc2(self.fc1(x)))\n",
    "    \n",
    "def inner_train(model, optimizer, num_iterations, criterion, data, targets):\n",
    "    for _ in range(num_iterations):\n",
    "        output = model(data) \n",
    "        loss = criterion(output, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def train(num_networks, network_size, num_iterations):\n",
    "    training_start = time.perf_counter()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    data = torch.zeros((5, 2), device='cuda')\n",
    "    targets = torch.ones((5, 1), device='cuda')\n",
    "    \n",
    "    models = []\n",
    "    optimizers = []\n",
    "    for _ in range(num_networks):\n",
    "        model = MLP(network_size).cuda()\n",
    "        models.append(model)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        optimizers.append(optimizer)\n",
    "\n",
    "    num_processes = num_networks\n",
    "    processes: List[Process] = []\n",
    "    for model, optimizer in zip(models, optimizers):\n",
    "        p = mp.Process(target=inner_train, args=(model, optimizer, num_iterations, criterion, data, targets,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    print(f\"Training {num_networks} model took {time.perf_counter() - training_start:.2f}s\")\n",
    "    \n",
    "def train2(num_networks, network_size, num_iterations):\n",
    "    training_start = time.perf_counter()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    data = torch.zeros((5, 2), device='cuda')\n",
    "    targets = torch.ones((5, 1), device='cuda')\n",
    "    \n",
    "    models = []\n",
    "    for _ in range(num_networks):\n",
    "        models.append(MLP(network_size).cuda())\n",
    "    for model in models:\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        for _ in range(num_iterations):\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(f\"Training {num_networks} model took {time.perf_counter() - training_start:.2f}s\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train(1, 10, 1000)\n",
    "\n",
    "    train(5, 10, 1000)\n",
    "\n",
    "    train(15, 10, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "img = cv2.imread('7b8902b02454db97903a146bc9e2121c.jpg', cv2.IMREAD_COLOR)[..., ::-1]\n",
    "h,w,_ = img.shape\n",
    "\n",
    "restored = cv2.resize(cv2.resize(img, (int(h/4), int(h/4))), (w,h), interpolation = cv2.INTER_NEAREST)\n",
    "plt.imshow(restored)\n",
    "\n",
    "cv2.imwrite(\"output.jpg\", restored[..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "grid_i, grid_j = torch.meshgrid(\n",
    "        torch.arange(-2, 4 + 2),\n",
    "        torch.arange(-1, 4 + 1), \n",
    "        indexing='ij'\n",
    "    )\n",
    "grid_coord = torch.cat((grid_i.unsqueeze(2), grid_j.unsqueeze(2)), 2).float() # w,h,2\n",
    "grid_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_coord_im2col = torch.as_strided(grid_coord, \n",
    "                size = (4, 4, 3,3, 2),\n",
    "                stride=(grid_coord.stride(0) * 1, grid_coord.stride(1) * 1, \n",
    "                        grid_coord.stride(0) * 1, grid_coord.stride(1) * 1, \n",
    "                        grid_coord.stride(2)) \n",
    "    )\n",
    "grid_coord_im2col[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.deform_conv import DeformConv2d, SeparableDeformConv2d\n",
    "import torch \n",
    "conv = SeparableDeformConv2d(16,96, 3, padding= 1, groups= 16)\n",
    "# This 2 conv_offset have the same number of parameter, but their output is different\n",
    "# All output channels will use the same offset map aggregate from all input channels\n",
    "conv_offset = torch.nn.Conv2d(16, 2 * 3 * 3 * 1, 3,1, 1, groups= 1) \n",
    "# Each output channel will use different offset map based on coresponding input channel\n",
    "conv_offset = torch.nn.Conv2d(16, 2 * 3 * 3 * 16, 3,1, 1, groups= 16)\n",
    "x = torch.rand(1,16,32,32)\n",
    "offset =conv_offset(x)\n",
    "\n",
    "out = conv(x, offset)\n",
    "out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.modules.flow.nested_flow import NestedAffineCoupling, InvertibleModuleWrapper, AffineCoupling, InvertibleSequential\n",
    "\n",
    "mod = InvertibleModuleWrapper(NestedAffineCoupling(4, 3, level=2, max_stack_level= 2, enforce_channel_on_base= True), disable= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4910, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(1,4,32,32)\n",
    "cond = torch.rand(1,3,32,32)\n",
    "# ((mod.inverse(mod(x, cond), cond) - x).abs() < 1e-7).all()\n",
    "((mod.inverse(mod(x, cond), cond) - x).abs()).mean()\n",
    "# mod(x, cond).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2 = InvertibleModuleWrapper(InvertibleSequential(InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel'), disable = True),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel'), disable = True),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel'), disable = True),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel'), disable = True),\n",
    "                            # InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'spatial')),\n",
    "                            ), disable = True)\n",
    "\n",
    "x2 = torch.rand(1,64,32,32)\n",
    "((mod2.inverse(mod2(x2)) - x2).abs()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                                            Output Shape              Param #\n",
       "===================================================================================================================\n",
       "InvertibleModuleWrapper                                           [1, 64, 128, 128]         --\n",
       "├─NestedAffineCoupling: 1-1                                       [1, 64, 128, 128]         --\n",
       "│    └─ModuleList: 2-11                                           --                        (recursive)\n",
       "│    │    └─ConditionalModule: 3-1                                [1, 32, 128, 128]         2,368\n",
       "│    └─ModuleList: 2-10                                           --                        (recursive)\n",
       "│    │    └─NestedAffineCoupling: 3-2                             [1, 32, 128, 128]         332,672\n",
       "│    └─ModuleList: 2-11                                           --                        (recursive)\n",
       "│    │    └─ConditionalModule: 3-3                                [1, 32, 128, 128]         (recursive)\n",
       "│    └─ModuleList: 2-12                                           --                        (recursive)\n",
       "│    │    └─NestedAffineCoupling: 3-4                             [1, 32, 128, 128]         332,672\n",
       "│    └─ModuleList: 2-11                                           --                        (recursive)\n",
       "│    │    └─ConditionalModule: 3-5                                [1, 32, 128, 128]         2,368\n",
       "│    └─ModuleList: 2-10                                           --                        (recursive)\n",
       "│    │    └─NestedAffineCoupling: 3-6                             [1, 32, 128, 128]         40,512\n",
       "│    └─ModuleList: 2-11                                           --                        (recursive)\n",
       "│    │    └─ConditionalModule: 3-7                                [1, 32, 128, 128]         (recursive)\n",
       "│    └─ModuleList: 2-12                                           --                        (recursive)\n",
       "│    │    └─NestedAffineCoupling: 3-8                             [1, 32, 128, 128]         40,512\n",
       "│    └─ModuleList: 2-11                                           --                        (recursive)\n",
       "│    │    └─ConditionalModule: 3-9                                [1, 32, 128, 128]         2,368\n",
       "│    └─ModuleList: 2-10                                           --                        (recursive)\n",
       "│    │    └─NestedAffineCoupling: 3-10                            [1, 32, 128, 128]         40,512\n",
       "│    └─ModuleList: 2-11                                           --                        (recursive)\n",
       "│    │    └─ConditionalModule: 3-11                               [1, 32, 128, 128]         (recursive)\n",
       "│    └─ModuleList: 2-12                                           --                        (recursive)\n",
       "│    │    └─NestedAffineCoupling: 3-12                            [1, 32, 128, 128]         40,512\n",
       "│    └─InvertibleSequential: 2-13                                 [1, 64, 128, 128]         --\n",
       "│    │    └─InvConv2d: 3-13                                       [1, 64, 128, 128]         4,096\n",
       "│    │    └─InvertibleLeakyReLU: 3-14                             [1, 64, 128, 128]         --\n",
       "│    │    └─InvConv2d: 3-15                                       [1, 64, 128, 128]         4,096\n",
       "===================================================================================================================\n",
       "Total params: 842,688\n",
       "Trainable params: 842,688\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.85\n",
       "===================================================================================================================\n",
       "Input size (MB): 6.29\n",
       "Forward/backward pass size (MB): 276.82\n",
       "Params size (MB): 3.37\n",
       "Estimated Total Size (MB): 286.49\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "mod = InvertibleModuleWrapper(NestedAffineCoupling(64, condition_channels=32, level=2, max_stack_level= 3, \n",
    "                                                   constrain_stack = True, custom_masking = None), disable= True)\n",
    "mod._fn.check_total_flow()\n",
    "summary(mod,[(1,64,128,128), (1,32,128,128)], depth= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "InvertibleModuleWrapper                                 [1, 64, 128, 128]         --\n",
       "├─InvertibleSequential: 1-1                             --                        --\n",
       "│    └─InvertibleModuleWrapper: 2-1                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-1                         --                        75,904\n",
       "│    └─InvertibleModuleWrapper: 2-2                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-2                         --                        303,360\n",
       "│    └─InvertibleModuleWrapper: 2-3                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-3                         --                        75,904\n",
       "│    └─InvertibleModuleWrapper: 2-4                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-4                         --                        303,360\n",
       "│    └─InvertibleModuleWrapper: 2-5                     [1, 64, 128, 128]         --\n",
       "│    │    └─AffineCoupling: 3-5                         --                        75,904\n",
       "=========================================================================================================\n",
       "Total params: 834,432\n",
       "Trainable params: 834,432\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 13.67\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 293.60\n",
       "Params size (MB): 3.34\n",
       "Estimated Total Size (MB): 296.94\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod2 = InvertibleModuleWrapper(InvertibleSequential(\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'spatial')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'spatial')),\n",
    "                            InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'channel')),\n",
    "                            # InvertibleModuleWrapper(AffineCoupling(in_channels=64, masking_type= 'spatial')),\n",
    "                            ))\n",
    "summary(mod2,[(1,64,128,128)], depth= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 2], dtype=torch.int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(1,2,4).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1 model took 0.08s\n",
      "Training 5 model took 0.29s\n",
      "Training 15 model took 0.87s\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "import time\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, network_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, network_size)\n",
    "        self.fc2 = nn.Linear(network_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc2(self.fc1(x)))\n",
    "    \n",
    "def inner_train(model, optimizer, num_iterations, criterion, data, targets):\n",
    "    for _ in range(num_iterations):\n",
    "        output = model(data) \n",
    "        loss = criterion(output, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "def train(num_networks, network_size, num_iterations):\n",
    "    training_start = time.perf_counter()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    data = torch.zeros((5, 2), device='cuda')\n",
    "    targets = torch.ones((5, 1), device='cuda')\n",
    "    \n",
    "    models = []\n",
    "    optimizers = []\n",
    "    for _ in range(num_networks):\n",
    "        model = MLP(network_size).cuda()\n",
    "        models.append(model)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        optimizers.append(optimizer)\n",
    "\n",
    "    num_processes = num_networks\n",
    "    processes: List[Process] = []\n",
    "    for model, optimizer in zip(models, optimizers):\n",
    "        p = mp.Process(target=inner_train, args=(model, optimizer, num_iterations, criterion, data, targets,))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    print(f\"Training {num_networks} model took {time.perf_counter() - training_start:.2f}s\")\n",
    "    \n",
    "def train2(num_networks, network_size, num_iterations):\n",
    "    training_start = time.perf_counter()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    data = torch.zeros((5, 2), device='cuda')\n",
    "    targets = torch.ones((5, 1), device='cuda')\n",
    "    \n",
    "    models = []\n",
    "    for _ in range(num_networks):\n",
    "        models.append(MLP(network_size).cuda())\n",
    "    for model in models:\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        for _ in range(num_iterations):\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print(f\"Training {num_networks} model took {time.perf_counter() - training_start:.2f}s\")\n",
    "\n",
    "\n",
    "train(1, 20, 1000)\n",
    "\n",
    "train(5, 20, 1000)\n",
    "\n",
    "train(15, 20, 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
